<!doctype html public "-//w3c//dtd html 4.0 transitional//en">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>MIRS2405-SOHT-0001 MIRS2405 ソフト詳細設計書</title>
<link rel=stylesheet href="../../style.css" type="text/css">
<link rel="shortcut icon" href="../../gullc_rogo.jpg" />
<script>
    setInterval("elm=document.getElementById('izutani');if(elm.style.visibility=='visible'){elm.style.visibility='hidden';}else{elm.style.visibility='visible';}",10000)
</script>

</head>

<body bgcolor="#000000" text="#ff00ff" link="#ff0000" vlink="#ffff00" alink="#0000ff">

    <img src="../../gullc_rogo.jpg" width="100">

<table class="table010">
<tr>
<th>名称</th>
<td class="title">MIRS2405 ソフト開発報告書</td>
</tr>
<tr>
<th>番号</th>
<td class="title">MIRS2405-soft-0003</td>
</tr>
</table>
<br>

<table class="table010">
<tr>
<th>版数</th>
<th>最終更新日</th>
<th>作成</th>
<th>承認</th>
<th>改訂記事</th>
</tr>
<tr>
<td>B01</td>
<td>2025.1.27</td>
<td>清拓実、平沢快斗、幸航輝</td>
<td></td>
<td>初版</td>
</tr>
</table>

<br>


  <!-- ここから本文-->
  <h3>目次</h3>
  <ol>
      <li><a href="#1">ドキュメント概要  </a><br></li>
      <li>
        <a href="#2">作成した主なプログラムと評価</a>
        <ul>
          <li><a href="#2-1">ロボットアーム</a></li>
          <li><a href="#2-2">デバイス間の通信</a></li>
          <li><a href="#2-3">年齢、性別の測定(対象者選別)</a></li>
          <li><a href="#2-4">身長の測定(対象者選別)</a></li>
        </ul>
      </li>
      <li><a href="#3">総括</a></li>
      <li><a href="#4">プログラムのソースコード</a></li>
  </ol>
  <hr>



  <h2><a name="1">1.ドキュメント概要</a></h2>
  <dd>
      <p>
          本ドキュメントはmirs2405𝔊𝔘𝔏𝔏ℭのソフトウェア開発報告書である。
      </p>

  </dd>
  
  <h2><a name="2">2.作成したプログラムと評価</a></h2>
  <div>
      <ul>
          <li>
              <h3><a name="2-1">ロボットアーム</a></h3>
              <!-- <iframe src="https://www.youtube.com/embed/yn59zjOSwMk?&autoplay=1&mute=1&controls=0&loop=1&playlist=yn59zjOSwMk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>-->
              <p>
                  ＜概要＞<br>
                  ロボット中央のフォトリフレクタ2つから白線と黒線の値を読み取った。その値からPID制御によりライントレースを行った。値が白線の閾値を超えた場合にUターンをさせた。<br>
                  <br>
                  ＜評価＞<br>
                  黒線の両サイドの値を取得する設計のため、直進および方向転換の際の追従精度は高かった。ただ、PIDのゲイン調整が上手くできず左右の振動が発生していた。<br>
                  <br>
                  ＜改良・改善案＞<br>
                  振動については、Dゲイン大きくすることで振動の抑制が可能と考えられる。<br>
                  ライントレース以外の方法として、LiDARを用いたSLAMとNavigationによる自立走行が考えられる。<br>
                  <br>
                  ＜対象プログラム＞<br>
                  Arduino: run_ctrl.ino (vel_ctrl.ino, motor.ino)<br>
              </p>
          </li>
          <li>
              <h3><a name="2-2">デバイス間の通信</a></h3>
              <iframe src="https://www.youtube.com/embed/5Q51hlnyWxo?&autoplay=1&mute=1&controls=0&loop=1&playlist=5Q51hlnyWxo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
              <p>
                  ＜概要＞<br>
                  USBシリアル通信を用いてraspiから各マイコンに指令を送ることでシステムの統合を行った。配列に識別番号、指令値を入れることでマイコン側がどの処理を行うかを決定した。esp32で取得したラジコン入力をraspiが受信することで動作開始のタイミングを決定できるようにした。<br>
                  <br>
                  ＜評価＞<br>
                  デバイス間の通信ではraspiで設定した識別番号通りの処理をマイコンが行い、指令値通りに制御することができた。ラジコン入力を加えたときに動作が開始することも確認した。<br>
                  <br>
                  ＜改良・改善案＞<br>
                  ラジコン入力で動作中のシステムを遠隔終了させることで、安全面が向上すると考えられる。<br>
                  <br>
                  ＜対象プログラム＞<br>
                  Arduino: raspi.ino<br>
                  pico: raspi.ino<br>
                  esp32: raspi.ino, radicon.ino<br>
                  raspi: send.py, receive.py<br>
                  Jetson: get_img.py<br>
              </p>
          </li>
          <li>
              <h3><a name="2-3">年齢、性別の測定(対象者選別)</a></h3>
              <iframe src="https://www.youtube.com/embed/cL-RALAbu_g?&autoplay=1&mute=1&controls=0&loop=1&playlist=cL-RALAbu_g" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe><br>
              ※この動画は顔検出の機能です。
              <p>
                  ＜概要＞<br>
                  OpenCV4.5.4から実装された顔検出および顔認証のAPIを用いた。<br>
                  <br>
                  ＜評価＞<br>
                  顔検出についてはfps1.5程度で15人同時に検出ができた。<br>
                  教室の一番後ろに立っている人やカメラ目線でない人でも検出ができた。<br>
                  顔認証については国会議員など写真を用いた場合おおむね認証できていたが、学生を用いた場合は正確な認証は行えなかった。<br>
                  <br>
                  ＜改良・改善案＞<br>
                  公開されているAPIは学習時に国会議員の画像を用いていた可能性があり精度が高かったと考えられる。既存の学習モデルに対して、学生の写真を用いファインチューニングを行うことで精度改善が期待できる。<br>
                  <br>
                  ＜対象プログラム＞<br>
                  Jetson: faceCV_recognition.py
              </p>
          </li>
   
          <li>
            <h3><a name="2-4">身長の測定(対象者選別)</a></h3>
            <iframe src="https://www.youtube.com/embed/cL-RALAbu_g?&autoplay=1&mute=1&controls=0&loop=1&playlist=cL-RALAbu_g" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe><br>
            ※この動画は顔検出の機能です。
            <p>
                ＜概要＞<br>
                OpenCV4.5.4から実装された顔検出および顔認証のAPIを用いた。<br>
                <br>
                ＜評価＞<br>
                顔検出についてはfps1.5程度で15人同時に検出ができた。<br>
                教室の一番後ろに立っている人やカメラ目線でない人でも検出ができた。<br>
                顔認証については国会議員など写真を用いた場合おおむね認証できていたが、学生を用いた場合は正確な認証は行えなかった。<br>
                <br>
                ＜改良・改善案＞<br>
                公開されているAPIは学習時に国会議員の画像を用いていた可能性があり精度が高かったと考えられる。既存の学習モデルに対して、学生の写真を用いファインチューニングを行うことで精度改善が期待できる。<br>
                <br>
                ＜対象プログラム＞<br>
                Jetson: faceCV_recognition.py
            </p>
        </li>
        </ul>
  </div>

  <h2><a name="3">3.総括</a></h2>
  <dd>
      ソフト開発のメインであった顔認証機能とLiDARを用いた走行が実装できなかったことは大変残念であった。<br>
      また、それらの開発に大半の時間を割いたため、ライントレースや撮影機能を中心に最低限しか実装できなかった。<br>
      要件定義や設計、開発の優先順位の決定が非常に重要であると感じた。<br>
      写真とデータのアップロードやWebページのソート機能については実装ができてよかった。<br>
      また、発表会前日のraspiの故障や社会実証実験直前での画像が表示できなくなる問題があったが、jetsonでの代替や別方法での画像表示など的確に対応できたことは大変良かったと思う。<br>
  </dd>

  <h2><a name="4">4.プログラムのソースコード</a></h2>
  <dd>
      <p>
          プログラムのソースコードを以下に示す。<br>
          <a href="https://github.com/puwaer/mirs2405">MIRS2405 𝔊𝔘𝔏𝔏ℭで使用したリポジトリ</a><br>
          <a href="https://github.com/puwaer/mirs2405/tree/main/program/honban">MIRS2405 𝔊𝔘𝔏𝔏ℭで最終的に使用したプログラム</a>
      </p>
  </dd>

 </body>
 <br>
 <hr>
 <br>
 <address>
  <a href="https://www2.denshi.numazu-ct.ac.jp/mirsdoc2/mirs2405">MIRS2031ドキュメント管理台帳</a>

</address>
 </html>